{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# NLTK\n",
    "NLTK is a Python module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some simple statistics on the Gutenberg corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to /Users/noah/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('gutenberg')\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192427"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emma = nltk.corpus.gutenberg.words('austen-emma.txt')\n",
    "len(emma)\n",
    "# all the words in one of the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'Emma',\n",
       " 'by',\n",
       " 'Jane',\n",
       " 'Austen',\n",
       " '1816',\n",
       " ']',\n",
       " 'VOLUME',\n",
       " 'I',\n",
       " 'CHAPTER',\n",
       " 'I',\n",
       " 'Emma',\n",
       " 'Woodhouse',\n",
       " ',',\n",
       " 'handsome',\n",
       " ',',\n",
       " 'clever',\n",
       " ',',\n",
       " 'and',\n",
       " 'rich']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emma[:20]\n",
    "# first 20 words from emma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/noah/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 25 26 austen-emma.txt\n",
      "5 26 17 austen-persuasion.txt\n",
      "5 28 22 austen-sense.txt\n",
      "4 34 79 bible-kjv.txt\n",
      "5 19 5 blake-poems.txt\n",
      "4 19 14 bryant-stories.txt\n",
      "4 18 12 burgess-busterbrown.txt\n",
      "4 20 13 carroll-alice.txt\n",
      "5 20 12 chesterton-ball.txt\n",
      "5 23 11 chesterton-brown.txt\n",
      "5 19 11 chesterton-thursday.txt\n",
      "4 21 25 edgeworth-parents.txt\n",
      "5 26 15 melville-moby_dick.txt\n",
      "5 52 11 milton-paradise.txt\n",
      "4 12 9 shakespeare-caesar.txt\n",
      "4 12 8 shakespeare-hamlet.txt\n",
      "4 12 7 shakespeare-macbeth.txt\n",
      "5 36 12 whitman-leaves.txt\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "from nltk.corpus import gutenberg\n",
    "for fileid in gutenberg.fileids():\n",
    "    num_chars = len(gutenberg.raw(fileid))\n",
    "#     print(num_chars)\n",
    "    num_words = len(gutenberg.words(fileid))\n",
    "#     print(num_words)\n",
    "    num_sents = len(gutenberg.sents(fileid))\n",
    "#     print(num_sents)\n",
    "    num_vocab = len(set(w.lower() for w in gutenberg.words(fileid)))\n",
    "    print(round(num_chars/num_words), round(num_words/num_sents), round(num_words/num_vocab), fileid)\n",
    "# for austen-emma.txt, 5 characters per words, 25 words per sentence, 26 words per vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Counting Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 11454),\n",
       " ('.', 6928),\n",
       " ('to', 5183),\n",
       " ('the', 4844),\n",
       " ('and', 4672),\n",
       " ('of', 4279),\n",
       " ('I', 3178),\n",
       " ('a', 3004),\n",
       " ('was', 2385),\n",
       " ('her', 2381)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "emma_counter = collections.Counter(emma)\n",
    "emma_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "865"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emma_counter['Emma']\n",
    "# frequency of the words 'emma'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Count Bigrams\n",
    "A bigram is a sequence of two words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (2, 3), (3, 4), (4, 5), (5, 6)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nltk.bigrams([1,2,3,4,5,6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[', 'Emma'),\n",
       " ('Emma', 'by'),\n",
       " ('by', 'Jane'),\n",
       " ('Jane', 'Austen'),\n",
       " ('Austen', '1816')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nltk.bigrams(emma))[:5]\n",
    "#the first five bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A bigram is an ngram where n is 2\n",
    "* A trigram is an ngram where n is 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[', 'Emma', 'by', 'Jane'),\n",
       " ('Emma', 'by', 'Jane', 'Austen'),\n",
       " ('by', 'Jane', 'Austen', '1816'),\n",
       " ('Jane', 'Austen', '1816', ']'),\n",
       " ('Austen', '1816', ']', 'VOLUME'),\n",
       " ('1816', ']', 'VOLUME', 'I'),\n",
       " (']', 'VOLUME', 'I', 'CHAPTER')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nltk.ngrams(emma,4))[:7]\n",
    "#the first seven 4grams in emma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercises\n",
    "1. Find the most frequent bigram in Austin's Emma.\n",
    "2. Find the most frequent bigram that begins with 'the'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((',', 'and'), 1879), (('Mr', '.'), 1153), ((\"'\", 's'), 932), ((';', 'and'), 866), (('.\"', '\"'), 757)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "bigrams=list(nltk.bigrams(emma))\n",
    "counts = Counter(bigrams)\n",
    "print(counts.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('the', 'same'), 98), (('the', 'very'), 92), (('the', 'world'), 76), (('the', 'other'), 73), (('the', 'first'), 69)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "bigrams=list(nltk.bigrams(emma))\n",
    "bigrams_the=[]\n",
    "for b in bigrams:\n",
    "    if b[0]=='the':\n",
    "        bigrams_the.append(b)\n",
    "  \n",
    "counts = Counter(bigrams_the)\n",
    "print(counts.most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Text Processing in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting\n",
    "* The function `sorted()` returns a sorted copy.\n",
    "* Sequences can be sorted in place with the `sort()` method.\n",
    "* Python 3 does not support sorting of lists with mixed contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 5, 9, 11]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = [2,5,9,1,11]\n",
    "sorted(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 5, 9, 1, 11]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 5, 9, 11]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-30e583885c1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfoo2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfoo2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "foo2 = [2,5,6,1,'a']\n",
    "sorted(foo2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sorting with a custom sorting criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['a','abc','b','c','aa','bb','cc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'aa', 'abc', 'b', 'bb', 'c', 'cc']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'aa', 'bb', 'cc', 'abc']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(l,key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abc', 'aa', 'bb', 'cc', 'a', 'b', 'c']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(l,key=len,reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_len(x):\n",
    "    return -len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abc', 'aa', 'bb', 'cc', 'a', 'b', 'c']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(l,key=my_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abc', 'aa', 'bb', 'cc', 'a', 'b', 'c']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(l,key = lambda x: -len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercises\n",
    "You're given data of the following form:\n",
    "\n",
    "```python\n",
    "namedat = dict()\n",
    "namedat['mc'] = ('Madonna', 45)\n",
    "namedat['sc'] = ('Steve', 41)\n",
    "```\n",
    "\n",
    "1. How would you print a list ordered by name?\n",
    "2. How would you print a list ordered by age?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sc': ('Steve', 41), 'mc': ('Madonna', 45)}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "namedat = dict()\n",
    "namedat['mc'] = ('Madonna', 45)\n",
    "namedat['sc'] = ('Steve', 41)\n",
    "\n",
    "\n",
    "dict(sorted(namedat.items(), key=lambda x: x[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Strings in Python\n",
    "* String is a base type.\n",
    "* Strings are sequences and can use operations like lists or tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = \"A string\"\n",
    "len(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A s'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "multifoo = \"\"\"A multiline \n",
    "string\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A multiline \\nstring'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multifoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My string'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"my string\".capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'capitalize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-858f66cc7b53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcapitalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"my string\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'capitalize' is not defined"
     ]
    }
   ],
   "source": [
    "capitalize(\"my string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MY STRING'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"my string\".upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my string'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"My String\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"my string with my other text\"\n",
    "a.count(\"my\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.find(\"with\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.find(\"nothing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Split\n",
    "* `split(sep)` is a central string operation.\n",
    "* It splits a string wherever `sep` occurs (blank space by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one', '::', 'two', '::', 'three']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = \"one :: two :: three\"\n",
    "foo.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one ', ' two ', ' three']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.split('::')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one', 'two', 'three']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.split(' :: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'a', 'test']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"this is a test\".split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Join\n",
    "* Join is another useful function/method in the string module.\n",
    "* It takes a list and joins the elements using some delimiter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'some', 'text', 'to', 'analyse']\n",
      "['analyse', 'is', 'some', 'text', 'this', 'to']\n",
      "analyse, is, some, text, this, to\n"
     ]
    }
   ],
   "source": [
    "text=\"this is some text to analyse\"\n",
    "words=text.split()\n",
    "print(words)\n",
    "words.sort()\n",
    "print(words)\n",
    "print(\", \".join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def censor(text):\n",
    "   'replace bad words in a text with XXX'\n",
    "   badwords = ['poo', 'bottom']\n",
    "   for b in badwords:\n",
    "      text = text.replace(b, 'XXX')\n",
    "   return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is all XXX and more XXX'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "censor(\"this is all poo and more poo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Text Preprocessing with NLTK\n",
    "#### Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/noah/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['This is a sentence.', 'This is another sentence.']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "text = \"This is a sentence. This is another sentence.\"\n",
    "nltk.sent_tokenize(text)\n",
    "# first tokenize the text and tokenize the words with for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "is\n",
      "a\n",
      "sentence\n",
      ".\n",
      "\n",
      "This\n",
      "is\n",
      "another\n",
      "sentence\n",
      ".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in nltk.sent_tokenize(text):\n",
    "    for w in nltk.word_tokenize(s):\n",
    "        print(w)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Part of speech tagging\n",
    "\n",
    "* Often it is useful to know whether a word is a noun, or an adjective, etc. These are called **parts of speech**.\n",
    "* NLTK has a part of speech tagger that tags a list of tokens.\n",
    "* The default list of parts of speech is fairly detailed but we can set a simplified version (called `universal` by NLTK).\n",
    "\n",
    "List of universal tagsets:\n",
    "\n",
    "| Tag | Meaning | English Examples |\n",
    "| --- | --- | --- |\n",
    "| `ADJ` | adjective | new, good, high, special, big, local |\n",
    "| `ADP` | adposition | on, of, at, with, by, into, under |\n",
    "| `ADV` | adverb | really, already, still, early, now |\n",
    "| `CONJ` | conjunction | and, or, but, if, while, although |\n",
    "| `DET` | determiner, article | the, a, some, most, every, no, which |\n",
    "| `NOUN` | noun | year, home, costs, time, Africa |\n",
    "| `NUM` | numeral | twenty-four, fourth, 1991, 14:24 |\n",
    "| `PRT` | particle | at, on, out, over per, that, up, with |\n",
    "| `PRON` | pronoun | he, their, her, its, my, I, us |\n",
    "| `VERB` | verb | is, say, told, given, playing, would |\n",
    "| `.` | punctuation marks | . , ; ! |\n",
    "| `X` | other | ersatz, esprit, dunno, gr8, univeristy |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![WordPosPipeline](WordPosPipeline.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/noah/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('this', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('test', 'NN')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.pos_tag([\"this\", \"is\", \"a\", \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /Users/noah/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('this', 'DET'), ('is', 'VERB'), ('a', 'DET'), ('test', 'NOUN')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"universal_tagset\")\n",
    "nltk.pos_tag([\"this\", \"is\", \"a\", \"test\"], tagset=\"universal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('this', 'DET'), ('is', 'VERB'), ('a', 'DET'), ('test', 'NOUN')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(nltk.word_tokenize(\"this is a test\"), tagset=\"universal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![SentPosPipeline](SentPosPipeline.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['This', 'is', 'a', 'sentence', '.'],\n",
       " ['This', 'is', 'another', 'sentence', '.']]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This is a sentence. This is another sentence.\"\n",
    "text_sent_tokens = [nltk.word_tokenize(s) for s in nltk.sent_tokenize(text)]\n",
    "text_sent_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('This', 'DET'),\n",
       "  ('is', 'VERB'),\n",
       "  ('a', 'DET'),\n",
       "  ('sentence', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('This', 'DET'),\n",
       "  ('is', 'VERB'),\n",
       "  ('another', 'DET'),\n",
       "  ('sentence', 'NOUN'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag_sents(text_sent_tokens, tagset=\"universal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Below is an implementation that has the same behaviour as `pos_tag_sents`. Hopefully this can help you understand how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_pos_tag_sents(text_sent_tokens, tagset=\"universal\"):\n",
    "    return [nltk.pos_tag(s, tagset=tagset) for s in text_sent_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('This', 'DET'),\n",
       "  ('is', 'VERB'),\n",
       "  ('a', 'DET'),\n",
       "  ('sentence', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('This', 'DET'),\n",
       "  ('is', 'VERB'),\n",
       "  ('another', 'DET'),\n",
       "  ('sentence', 'NOUN'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_pos_tag_sents(text_sent_tokens, tagset=\"universal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Stemming\n",
    "\n",
    "* Often it is useful to remove information such as verb form, or the difference between singular and plural.\n",
    "* NLTK offers stemming, which removes suffixes.\n",
    "    * The Porter stemmer is a popular stemmer.\n",
    "* The remaining stem is not a word but can be used, for example, by search engines (we'll see more of this in another lecture)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'book'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.stem(\"books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.stem(\"running\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.stem(\"run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goe'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.stem(\"goes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', \"'m\", 'run', 'and', 'he', 'goe']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s.stem(w) for w in nltk.word_tokenize(\"I'm running and he goes\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercises\n",
    "1.  What is the sentence with the largest number of tokens\n",
    "    in Austen's \"Emma\"?\n",
    "2. What is the number of distinct stems in Austen's \"Emma\"?\n",
    "3. What is the most ambiguous stem in Austen's \"Emma\"?\n",
    "    (meaning, which stem in Austen's \"Emma\" maps to the\n",
    "    largest number of distinct tokens?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['While', 'he', 'lived', ',', 'it', 'must', 'be', 'only', 'an', 'engagement', ';', 'but', 'she', 'flattered', 'herself', ',', 'that', 'if', 'divested', 'of', 'the', 'danger', 'of', 'drawing', 'her', 'away', ',', 'it', 'might', 'become', 'an', 'increase', 'of', 'comfort', 'to', 'him.', '--', 'How', 'to', 'do', 'her', 'best', 'by', 'Harriet', ',', 'was', 'of', 'more', 'difficult', 'decision', ';', '--', 'how', 'to', 'spare', 'her', 'from', 'any', 'unnecessary', 'pain', ';', 'how', 'to', 'make', 'her', 'any', 'possible', 'atonement', ';', 'how', 'to', 'appear', 'least', 'her', 'enemy', '?', '--', 'On', 'these', 'subjects', ',', 'her', 'perplexity', 'and', 'distress', 'were', 'very', 'great', '--', 'and', 'her', 'mind', 'had', 'to', 'pass', 'again', 'and', 'again', 'through', 'every', 'bitter', 'reproach', 'and', 'sorrowful', 'regret', 'that', 'had', 'ever', 'surrounded', 'it.', '--', 'She', 'could', 'only', 'resolve', 'at', 'last', ',', 'that', 'she', 'would', 'still', 'avoid', 'a', 'meeting', 'with', 'her', ',', 'and', 'communicate', 'all', 'that', 'need', 'be', 'told', 'by', 'letter', ';', 'that', 'it', 'would', 'be', 'inexpressibly', 'desirable', 'to', 'have', 'her', 'removed', 'just', 'now', 'for', 'a', 'time', 'from', 'Highbury', ',', 'and', '--', 'indulging', 'in', 'one', 'scheme', 'more', '--', 'nearly', 'resolve', ',', 'that', 'it', 'might', 'be', 'practicable', 'to', 'get', 'an', 'invitation', 'for', 'her', 'to', 'Brunswick', 'Square.', '--', 'Isabella', 'had', 'been', 'pleased', 'with', 'Harriet', ';', 'and', 'a', 'few', 'weeks', 'spent', 'in', 'London', 'must', 'give', 'her', 'some', 'amusement.', '--', 'She', 'did', 'not', 'think', 'it', 'in', 'Harriet', \"'s\", 'nature', 'to', 'escape', 'being', 'benefited', 'by', 'novelty', 'and', 'variety', ',', 'by', 'the', 'streets', ',', 'the', 'shops', ',', 'and', 'the', 'children.', '--', 'At', 'any', 'rate', ',', 'it', 'would', 'be', 'a', 'proof', 'of', 'attention', 'and', 'kindness', 'in', 'herself', ',', 'from', 'whom', 'every', 'thing', 'was', 'due', ';', 'a', 'separation', 'for', 'the', 'present', ';', 'an', 'averting', 'of', 'the', 'evil', 'day', ',', 'when', 'they', 'must', 'all', 'be', 'together', 'again', '.'] 275\n"
     ]
    }
   ],
   "source": [
    "# 1) sentence with the largest number of tokens\n",
    "emmaa=gutenberg.raw('austen-emma.txt')\n",
    "# nltk.sent_tokenize(emmaa)\n",
    "emmaa_sent_tokens = [nltk.word_tokenize(s) for s in nltk.sent_tokenize(emmaa)]\n",
    "longestLen=0\n",
    "longestSen=''\n",
    "for e in emmaa_sent_tokens:\n",
    "    if len(e)>longestLen:\n",
    "        longestSen=e\n",
    "        longestLen=len(e)\n",
    "print(longestSen,longestLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'emma',\n",
       " 'by',\n",
       " 'jane',\n",
       " 'austen',\n",
       " '1816',\n",
       " ']',\n",
       " 'volum',\n",
       " 'i',\n",
       " 'chapter',\n",
       " 'i',\n",
       " 'emma',\n",
       " 'woodhous',\n",
       " ',',\n",
       " 'handsom',\n",
       " ',',\n",
       " 'clever',\n",
       " ',',\n",
       " 'and',\n",
       " 'rich',\n",
       " ',',\n",
       " 'with',\n",
       " 'a',\n",
       " 'comfort',\n",
       " 'home',\n",
       " 'and',\n",
       " 'happi',\n",
       " 'disposit',\n",
       " ',',\n",
       " 'seem',\n",
       " 'to',\n",
       " 'unit',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'best',\n",
       " 'bless',\n",
       " 'of',\n",
       " 'exist',\n",
       " ';',\n",
       " 'and',\n",
       " 'had',\n",
       " 'live',\n",
       " 'nearli',\n",
       " 'twenty-on',\n",
       " 'year',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " 'with',\n",
       " 'veri',\n",
       " 'littl',\n",
       " 'to',\n",
       " 'distress',\n",
       " 'or',\n",
       " 'vex',\n",
       " 'her',\n",
       " '.',\n",
       " 'she',\n",
       " 'wa',\n",
       " 'the',\n",
       " 'youngest',\n",
       " 'of',\n",
       " 'the',\n",
       " 'two',\n",
       " 'daughter',\n",
       " 'of',\n",
       " 'a',\n",
       " 'most',\n",
       " 'affection',\n",
       " ',',\n",
       " 'indulg',\n",
       " 'father',\n",
       " ';',\n",
       " 'and',\n",
       " 'had',\n",
       " ',',\n",
       " 'in',\n",
       " 'consequ',\n",
       " 'of',\n",
       " 'her',\n",
       " 'sister',\n",
       " \"'s\",\n",
       " 'marriag',\n",
       " ',',\n",
       " 'been',\n",
       " 'mistress',\n",
       " 'of',\n",
       " 'hi',\n",
       " 'hous',\n",
       " 'from',\n",
       " 'a',\n",
       " 'veri',\n",
       " 'earli',\n",
       " 'period',\n",
       " '.',\n",
       " 'her',\n",
       " 'mother',\n",
       " 'had',\n",
       " 'die',\n",
       " 'too',\n",
       " 'long',\n",
       " 'ago',\n",
       " 'for',\n",
       " 'her',\n",
       " 'to',\n",
       " 'have',\n",
       " 'more',\n",
       " 'than',\n",
       " 'an',\n",
       " 'indistinct',\n",
       " 'remembr',\n",
       " 'of',\n",
       " 'her',\n",
       " 'caress',\n",
       " ';',\n",
       " 'and',\n",
       " 'her',\n",
       " 'place',\n",
       " 'had',\n",
       " 'been',\n",
       " 'suppli',\n",
       " 'by',\n",
       " 'an',\n",
       " 'excel',\n",
       " 'woman',\n",
       " 'as',\n",
       " 'gover',\n",
       " ',',\n",
       " 'who',\n",
       " 'had',\n",
       " 'fallen',\n",
       " 'littl',\n",
       " 'short',\n",
       " 'of',\n",
       " 'a',\n",
       " 'mother',\n",
       " 'in',\n",
       " 'affect',\n",
       " '.',\n",
       " 'sixteen',\n",
       " 'year',\n",
       " 'had',\n",
       " 'miss',\n",
       " 'taylor',\n",
       " 'been',\n",
       " 'in',\n",
       " 'mr.',\n",
       " 'woodhous',\n",
       " \"'s\",\n",
       " 'famili',\n",
       " ',',\n",
       " 'less',\n",
       " 'as',\n",
       " 'a',\n",
       " 'gover',\n",
       " 'than',\n",
       " 'a',\n",
       " 'friend',\n",
       " ',',\n",
       " 'veri',\n",
       " 'fond',\n",
       " 'of',\n",
       " 'both',\n",
       " 'daughter',\n",
       " ',',\n",
       " 'but',\n",
       " 'particularli',\n",
       " 'of',\n",
       " 'emma',\n",
       " '.',\n",
       " 'between',\n",
       " '_them_',\n",
       " 'it',\n",
       " 'wa',\n",
       " 'more',\n",
       " 'the',\n",
       " 'intimaci',\n",
       " 'of',\n",
       " 'sister',\n",
       " '.',\n",
       " 'even',\n",
       " 'befor',\n",
       " 'miss',\n",
       " 'taylor',\n",
       " 'had',\n",
       " 'ceas',\n",
       " 'to',\n",
       " 'hold',\n",
       " 'the',\n",
       " 'nomin',\n",
       " 'offic',\n",
       " 'of',\n",
       " 'gover',\n",
       " ',',\n",
       " 'the',\n",
       " 'mild',\n",
       " 'of',\n",
       " 'her',\n",
       " 'temper',\n",
       " 'had',\n",
       " 'hardli',\n",
       " 'allow',\n",
       " 'her',\n",
       " 'to',\n",
       " 'impos',\n",
       " 'ani',\n",
       " 'restraint',\n",
       " ';',\n",
       " 'and',\n",
       " 'the',\n",
       " 'shadow',\n",
       " 'of',\n",
       " 'author',\n",
       " 'be',\n",
       " 'now',\n",
       " 'long',\n",
       " 'pass',\n",
       " 'away',\n",
       " ',',\n",
       " 'they',\n",
       " 'had',\n",
       " 'been',\n",
       " 'live',\n",
       " 'togeth',\n",
       " 'as',\n",
       " 'friend',\n",
       " 'and',\n",
       " 'friend',\n",
       " 'veri',\n",
       " 'mutual',\n",
       " 'attach',\n",
       " ',',\n",
       " 'and',\n",
       " 'emma',\n",
       " 'do',\n",
       " 'just',\n",
       " 'what',\n",
       " 'she',\n",
       " 'like',\n",
       " ';',\n",
       " 'highli',\n",
       " 'esteem',\n",
       " 'miss',\n",
       " 'taylor',\n",
       " \"'s\",\n",
       " 'judgment',\n",
       " ',',\n",
       " 'but',\n",
       " 'direct',\n",
       " 'chiefli',\n",
       " 'by',\n",
       " 'her',\n",
       " 'own',\n",
       " '.',\n",
       " 'the',\n",
       " 'real',\n",
       " 'evil',\n",
       " ',',\n",
       " 'inde',\n",
       " ',',\n",
       " 'of',\n",
       " 'emma',\n",
       " \"'s\",\n",
       " 'situat',\n",
       " 'were',\n",
       " 'the',\n",
       " 'power',\n",
       " 'of',\n",
       " 'have',\n",
       " 'rather',\n",
       " 'too',\n",
       " 'much',\n",
       " 'her',\n",
       " 'own',\n",
       " 'way',\n",
       " ',',\n",
       " 'and',\n",
       " 'a',\n",
       " 'disposit',\n",
       " 'to',\n",
       " 'think',\n",
       " 'a',\n",
       " 'littl',\n",
       " 'too',\n",
       " 'well',\n",
       " 'of',\n",
       " 'herself',\n",
       " ';',\n",
       " 'these',\n",
       " 'were',\n",
       " 'the',\n",
       " 'disadvantag',\n",
       " 'which',\n",
       " 'threaten',\n",
       " 'alloy',\n",
       " 'to',\n",
       " 'her',\n",
       " 'mani',\n",
       " 'enjoy',\n",
       " '.',\n",
       " 'the',\n",
       " 'danger',\n",
       " ',',\n",
       " 'howev',\n",
       " ',',\n",
       " 'wa',\n",
       " 'at',\n",
       " 'present',\n",
       " 'so',\n",
       " 'unperceiv',\n",
       " ',',\n",
       " 'that',\n",
       " 'they',\n",
       " 'did',\n",
       " 'not',\n",
       " 'by',\n",
       " 'ani',\n",
       " 'mean',\n",
       " 'rank',\n",
       " 'as',\n",
       " 'misfortun',\n",
       " 'with',\n",
       " 'her',\n",
       " '.',\n",
       " 'sorrow',\n",
       " 'came',\n",
       " '--',\n",
       " 'a',\n",
       " 'gentl',\n",
       " 'sorrow',\n",
       " '--',\n",
       " 'but',\n",
       " 'not',\n",
       " 'at',\n",
       " 'all',\n",
       " 'in',\n",
       " 'the',\n",
       " 'shape',\n",
       " 'of',\n",
       " 'ani',\n",
       " 'disagre',\n",
       " 'consciousness.',\n",
       " '--',\n",
       " 'miss',\n",
       " 'taylor',\n",
       " 'marri',\n",
       " '.',\n",
       " 'it',\n",
       " 'wa',\n",
       " 'miss',\n",
       " 'taylor',\n",
       " \"'s\",\n",
       " 'loss',\n",
       " 'which',\n",
       " 'first',\n",
       " 'brought',\n",
       " 'grief',\n",
       " '.',\n",
       " 'it',\n",
       " 'wa',\n",
       " 'on',\n",
       " 'the',\n",
       " 'wedding-day',\n",
       " 'of',\n",
       " 'thi',\n",
       " 'belov',\n",
       " 'friend',\n",
       " 'that',\n",
       " 'emma',\n",
       " 'first',\n",
       " 'sat',\n",
       " 'in',\n",
       " 'mourn',\n",
       " 'thought',\n",
       " 'of',\n",
       " 'ani',\n",
       " 'continu',\n",
       " '.',\n",
       " 'the',\n",
       " 'wed',\n",
       " 'over',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'bride-peopl',\n",
       " 'gone',\n",
       " ',',\n",
       " 'her',\n",
       " 'father',\n",
       " 'and',\n",
       " 'herself',\n",
       " 'were',\n",
       " 'left',\n",
       " 'to',\n",
       " 'dine',\n",
       " 'togeth',\n",
       " ',',\n",
       " 'with',\n",
       " 'no',\n",
       " 'prospect',\n",
       " 'of',\n",
       " 'a',\n",
       " 'third',\n",
       " 'to',\n",
       " 'cheer',\n",
       " 'a',\n",
       " 'long',\n",
       " 'even',\n",
       " '.',\n",
       " 'her',\n",
       " 'father',\n",
       " 'compos',\n",
       " 'himself',\n",
       " 'to',\n",
       " 'sleep',\n",
       " 'after',\n",
       " 'dinner',\n",
       " ',',\n",
       " 'as',\n",
       " 'usual',\n",
       " ',',\n",
       " 'and',\n",
       " 'she',\n",
       " 'had',\n",
       " 'then',\n",
       " 'onli',\n",
       " 'to',\n",
       " 'sit',\n",
       " 'and',\n",
       " 'think',\n",
       " 'of',\n",
       " 'what',\n",
       " 'she',\n",
       " 'had',\n",
       " 'lost',\n",
       " '.',\n",
       " 'the',\n",
       " 'event',\n",
       " 'had',\n",
       " 'everi',\n",
       " 'promis',\n",
       " 'of',\n",
       " 'happi',\n",
       " 'for',\n",
       " 'her',\n",
       " 'friend',\n",
       " '.',\n",
       " 'mr.',\n",
       " 'weston',\n",
       " 'wa',\n",
       " 'a',\n",
       " 'man',\n",
       " 'of',\n",
       " 'unexception',\n",
       " 'charact',\n",
       " ',',\n",
       " 'easi',\n",
       " 'fortun',\n",
       " ',',\n",
       " 'suitabl',\n",
       " 'age',\n",
       " ',',\n",
       " 'and',\n",
       " 'pleasant',\n",
       " 'manner',\n",
       " ';',\n",
       " 'and',\n",
       " 'there',\n",
       " 'wa',\n",
       " 'some',\n",
       " 'satisfact',\n",
       " 'in',\n",
       " 'consid',\n",
       " 'with',\n",
       " 'what',\n",
       " 'self-deni',\n",
       " ',',\n",
       " 'gener',\n",
       " 'friendship',\n",
       " 'she',\n",
       " 'had',\n",
       " 'alway',\n",
       " 'wish',\n",
       " 'and',\n",
       " 'promot',\n",
       " 'the',\n",
       " 'match',\n",
       " ';',\n",
       " 'but',\n",
       " 'it',\n",
       " 'wa',\n",
       " 'a',\n",
       " 'black',\n",
       " 'morn',\n",
       " \"'s\",\n",
       " 'work',\n",
       " 'for',\n",
       " 'her',\n",
       " '.',\n",
       " 'the',\n",
       " 'want',\n",
       " 'of',\n",
       " 'miss',\n",
       " 'taylor',\n",
       " 'would',\n",
       " 'be',\n",
       " 'felt',\n",
       " 'everi',\n",
       " 'hour',\n",
       " 'of',\n",
       " 'everi',\n",
       " 'day',\n",
       " '.',\n",
       " 'she',\n",
       " 'recal',\n",
       " 'her',\n",
       " 'past',\n",
       " 'kind',\n",
       " '--',\n",
       " 'the',\n",
       " 'kind',\n",
       " ',',\n",
       " 'the',\n",
       " 'affect',\n",
       " 'of',\n",
       " 'sixteen',\n",
       " 'year',\n",
       " '--',\n",
       " 'how',\n",
       " 'she',\n",
       " 'had',\n",
       " 'taught',\n",
       " 'and',\n",
       " 'how',\n",
       " 'she',\n",
       " 'had',\n",
       " 'play',\n",
       " 'with',\n",
       " 'her',\n",
       " 'from',\n",
       " 'five',\n",
       " 'year',\n",
       " 'old',\n",
       " '--',\n",
       " 'how',\n",
       " 'she',\n",
       " 'had',\n",
       " 'devot',\n",
       " 'all',\n",
       " 'her',\n",
       " 'power',\n",
       " 'to',\n",
       " 'attach',\n",
       " 'and',\n",
       " 'amus',\n",
       " 'her',\n",
       " 'in',\n",
       " 'health',\n",
       " '--',\n",
       " 'and',\n",
       " 'how',\n",
       " 'nurs',\n",
       " 'her',\n",
       " 'through',\n",
       " 'the',\n",
       " 'variou',\n",
       " 'ill',\n",
       " 'of',\n",
       " 'childhood',\n",
       " '.',\n",
       " 'a',\n",
       " 'larg',\n",
       " 'debt',\n",
       " 'of',\n",
       " 'gratitud',\n",
       " 'wa',\n",
       " 'owe',\n",
       " 'here',\n",
       " ';',\n",
       " 'but',\n",
       " 'the',\n",
       " 'intercours',\n",
       " 'of',\n",
       " 'the',\n",
       " 'last',\n",
       " 'seven',\n",
       " 'year',\n",
       " ',',\n",
       " 'the',\n",
       " 'equal',\n",
       " 'foot',\n",
       " 'and',\n",
       " 'perfect',\n",
       " 'unreserv',\n",
       " 'which',\n",
       " 'had',\n",
       " 'soon',\n",
       " 'follow',\n",
       " 'isabella',\n",
       " \"'s\",\n",
       " 'marriag',\n",
       " ',',\n",
       " 'on',\n",
       " 'their',\n",
       " 'be',\n",
       " 'left',\n",
       " 'to',\n",
       " 'each',\n",
       " 'other',\n",
       " ',',\n",
       " 'wa',\n",
       " 'yet',\n",
       " 'a',\n",
       " 'dearer',\n",
       " ',',\n",
       " 'tender',\n",
       " 'recollect',\n",
       " '.',\n",
       " 'she',\n",
       " 'had',\n",
       " 'been',\n",
       " 'a',\n",
       " 'friend',\n",
       " 'and',\n",
       " 'companion',\n",
       " 'such',\n",
       " 'as',\n",
       " 'few',\n",
       " 'possess',\n",
       " ':',\n",
       " 'intellig',\n",
       " ',',\n",
       " 'well-inform',\n",
       " ',',\n",
       " 'use',\n",
       " ',',\n",
       " 'gentl',\n",
       " ',',\n",
       " 'know',\n",
       " 'all',\n",
       " 'the',\n",
       " 'way',\n",
       " 'of',\n",
       " 'the',\n",
       " 'famili',\n",
       " ',',\n",
       " 'interest',\n",
       " 'in',\n",
       " 'all',\n",
       " 'it',\n",
       " 'concern',\n",
       " ',',\n",
       " 'and',\n",
       " 'peculiarli',\n",
       " 'interest',\n",
       " 'in',\n",
       " 'herself',\n",
       " ',',\n",
       " 'in',\n",
       " 'everi',\n",
       " 'pleasur',\n",
       " ',',\n",
       " 'everi',\n",
       " 'scheme',\n",
       " 'of',\n",
       " 'her',\n",
       " '--',\n",
       " 'one',\n",
       " 'to',\n",
       " 'whom',\n",
       " 'she',\n",
       " 'could',\n",
       " 'speak',\n",
       " 'everi',\n",
       " 'thought',\n",
       " 'as',\n",
       " 'it',\n",
       " 'aros',\n",
       " ',',\n",
       " 'and',\n",
       " 'who',\n",
       " 'had',\n",
       " 'such',\n",
       " 'an',\n",
       " 'affect',\n",
       " 'for',\n",
       " 'her',\n",
       " 'as',\n",
       " 'could',\n",
       " 'never',\n",
       " 'find',\n",
       " 'fault',\n",
       " '.',\n",
       " 'how',\n",
       " 'wa',\n",
       " 'she',\n",
       " 'to',\n",
       " 'bear',\n",
       " 'the',\n",
       " 'chang',\n",
       " '?',\n",
       " '--',\n",
       " 'it',\n",
       " 'wa',\n",
       " 'true',\n",
       " 'that',\n",
       " 'her',\n",
       " 'friend',\n",
       " 'wa',\n",
       " 'go',\n",
       " 'onli',\n",
       " 'half',\n",
       " 'a',\n",
       " 'mile',\n",
       " 'from',\n",
       " 'them',\n",
       " ';',\n",
       " 'but',\n",
       " 'emma',\n",
       " 'wa',\n",
       " 'awar',\n",
       " 'that',\n",
       " 'great',\n",
       " 'must',\n",
       " 'be',\n",
       " 'the',\n",
       " 'differ',\n",
       " 'between',\n",
       " 'a',\n",
       " 'mrs.',\n",
       " 'weston',\n",
       " ',',\n",
       " 'onli',\n",
       " 'half',\n",
       " 'a',\n",
       " 'mile',\n",
       " 'from',\n",
       " 'them',\n",
       " ',',\n",
       " 'and',\n",
       " 'a',\n",
       " 'miss',\n",
       " 'taylor',\n",
       " 'in',\n",
       " 'the',\n",
       " 'hous',\n",
       " ';',\n",
       " 'and',\n",
       " 'with',\n",
       " 'all',\n",
       " 'her',\n",
       " 'advantag',\n",
       " ',',\n",
       " 'natur',\n",
       " 'and',\n",
       " 'domest',\n",
       " ',',\n",
       " 'she',\n",
       " 'wa',\n",
       " 'now',\n",
       " 'in',\n",
       " 'great',\n",
       " 'danger',\n",
       " 'of',\n",
       " 'suffer',\n",
       " 'from',\n",
       " 'intellectu',\n",
       " 'solitud',\n",
       " '.',\n",
       " 'she',\n",
       " 'dearli',\n",
       " 'love',\n",
       " 'her',\n",
       " 'father',\n",
       " ',',\n",
       " 'but',\n",
       " 'he',\n",
       " 'wa',\n",
       " 'no',\n",
       " 'companion',\n",
       " 'for',\n",
       " 'her',\n",
       " '.',\n",
       " 'he',\n",
       " 'could',\n",
       " 'not',\n",
       " 'meet',\n",
       " 'her',\n",
       " 'in',\n",
       " 'convers',\n",
       " ',',\n",
       " 'ration',\n",
       " 'or',\n",
       " 'play',\n",
       " '.',\n",
       " 'the',\n",
       " 'evil',\n",
       " 'of',\n",
       " 'the',\n",
       " 'actual',\n",
       " 'dispar',\n",
       " 'in',\n",
       " 'their',\n",
       " 'age',\n",
       " '(',\n",
       " 'and',\n",
       " 'mr.',\n",
       " 'woodhous',\n",
       " 'had',\n",
       " 'not',\n",
       " 'marri',\n",
       " 'earli',\n",
       " ')',\n",
       " 'wa',\n",
       " 'much',\n",
       " 'increas',\n",
       " 'by',\n",
       " 'hi',\n",
       " 'constitut',\n",
       " 'and',\n",
       " 'habit',\n",
       " ';',\n",
       " 'for',\n",
       " 'have',\n",
       " 'been',\n",
       " 'a',\n",
       " 'valetudinarian',\n",
       " 'all',\n",
       " 'hi',\n",
       " 'life',\n",
       " ',',\n",
       " 'without',\n",
       " 'activ',\n",
       " 'of',\n",
       " 'mind',\n",
       " 'or',\n",
       " 'bodi',\n",
       " ',',\n",
       " 'he',\n",
       " 'wa',\n",
       " 'a',\n",
       " 'much',\n",
       " 'older',\n",
       " 'man',\n",
       " 'in',\n",
       " 'way',\n",
       " 'than',\n",
       " 'in',\n",
       " 'year',\n",
       " ';',\n",
       " 'and',\n",
       " 'though',\n",
       " 'everywher',\n",
       " 'belov',\n",
       " 'for',\n",
       " 'the',\n",
       " 'friendli',\n",
       " 'of',\n",
       " 'hi',\n",
       " 'heart',\n",
       " 'and',\n",
       " 'hi',\n",
       " 'amiabl',\n",
       " 'temper',\n",
       " ',',\n",
       " 'hi',\n",
       " 'talent',\n",
       " 'could',\n",
       " 'not',\n",
       " 'have',\n",
       " 'recommend',\n",
       " 'him',\n",
       " 'at',\n",
       " 'ani',\n",
       " 'time',\n",
       " '.',\n",
       " 'her',\n",
       " 'sister',\n",
       " ',',\n",
       " 'though',\n",
       " 'compar',\n",
       " 'but',\n",
       " 'littl',\n",
       " 'remov',\n",
       " 'by',\n",
       " 'matrimoni',\n",
       " ',',\n",
       " 'be',\n",
       " 'settl',\n",
       " 'in',\n",
       " 'london',\n",
       " ',',\n",
       " 'onli',\n",
       " 'sixteen',\n",
       " 'mile',\n",
       " 'off',\n",
       " ',',\n",
       " 'wa',\n",
       " 'much',\n",
       " 'beyond',\n",
       " 'her',\n",
       " 'daili',\n",
       " 'reach',\n",
       " ';',\n",
       " 'and',\n",
       " 'mani',\n",
       " 'a',\n",
       " 'long',\n",
       " 'octob',\n",
       " 'and',\n",
       " 'novemb',\n",
       " 'even',\n",
       " 'must',\n",
       " 'be',\n",
       " 'struggl',\n",
       " 'through',\n",
       " 'at',\n",
       " 'hartfield',\n",
       " ',',\n",
       " 'befor',\n",
       " 'christma',\n",
       " 'brought',\n",
       " 'the',\n",
       " 'next',\n",
       " 'visit',\n",
       " 'from',\n",
       " 'isabella',\n",
       " 'and',\n",
       " 'her',\n",
       " 'husband',\n",
       " ',',\n",
       " 'and',\n",
       " 'their',\n",
       " 'littl',\n",
       " 'children',\n",
       " ',',\n",
       " 'to',\n",
       " 'fill',\n",
       " 'the',\n",
       " 'hous',\n",
       " ',',\n",
       " 'and',\n",
       " 'give',\n",
       " 'her',\n",
       " 'pleasant',\n",
       " 'societi',\n",
       " 'again',\n",
       " '.',\n",
       " 'highburi',\n",
       " ',',\n",
       " 'the',\n",
       " 'larg',\n",
       " 'and',\n",
       " 'popul',\n",
       " 'villag',\n",
       " ',',\n",
       " 'almost',\n",
       " 'amount',\n",
       " 'to',\n",
       " 'a',\n",
       " 'town',\n",
       " ',',\n",
       " 'to',\n",
       " 'which',\n",
       " 'hartfield',\n",
       " ',',\n",
       " 'in',\n",
       " 'spite',\n",
       " 'of',\n",
       " 'it',\n",
       " 'separ',\n",
       " 'lawn',\n",
       " ',',\n",
       " 'and',\n",
       " 'shrubberi',\n",
       " ',',\n",
       " 'and',\n",
       " 'name',\n",
       " ',',\n",
       " 'did',\n",
       " 'realli',\n",
       " 'belong',\n",
       " ',',\n",
       " 'afford',\n",
       " 'her',\n",
       " 'no',\n",
       " 'equal',\n",
       " '.',\n",
       " 'the',\n",
       " 'woodhous',\n",
       " 'were',\n",
       " 'first',\n",
       " 'in',\n",
       " 'consequ',\n",
       " 'there',\n",
       " '.',\n",
       " 'all',\n",
       " 'look',\n",
       " 'up',\n",
       " ...]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) number of different stems in emma\n",
    "emmaa_sent_tokens2=nltk.word_tokenize(emmaa)\n",
    "stems=[s.stem(w) for w in emmaa_sent_tokens2]\n",
    "stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5369"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_stems=set(stems)\n",
    "len(set_stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 12016),\n",
       " ('.', 6346),\n",
       " ('the', 5201),\n",
       " ('to', 5181),\n",
       " ('and', 4877),\n",
       " ('of', 4284),\n",
       " ('i', 3177),\n",
       " ('a', 3124),\n",
       " ('--', 3100),\n",
       " ('it', 2625)]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3)\n",
    "import collections\n",
    "emma_stems_counter = collections.Counter(stems)\n",
    "emma_stems_counter.most_common(10)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "interpreter": {
   "hash": "a7b63e7410c98f344f02082f10d790581d1dba1eeb1c8fe30f342f6109f0429e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
